{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --user numpy\n",
    "# pip install --user pandas\n",
    "# pip install --user seaborn\n",
    "# pip install --user matplotliob\n",
    "# pip install --user sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "block:loaddata"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "path = \"data/\"\n",
    "\n",
    "PREDICTION_LABEL = 'Survived'\n",
    "\n",
    "test_df = pd.read_csv(path + \"test.csv\")\n",
    "train_df = pd.read_csv(path + \"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "skip"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cabin</th>\n",
       "      <td>687</td>\n",
       "      <td>77.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>177</td>\n",
       "      <td>19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticket</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Total     %\n",
       "Cabin       687  77.1\n",
       "Age         177  19.9\n",
       "Embarked      2   0.2\n",
       "Fare          0   0.0\n",
       "Ticket        0   0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = train_df.isnull().sum().sort_values(ascending=False)\n",
    "percent_1 = train_df.isnull().sum()/train_df.isnull().count()*100\n",
    "percent_2 = (round(percent_1, 1)).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent_2], axis=1, keys=['Total', '%'])\n",
    "missing_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "block:datapreprocessing",
     "prev:loaddata"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    537\n",
       "0    354\n",
       "Name: not_alone, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n",
    "    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n",
    "    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n",
    "    dataset['not_alone'] = dataset['not_alone'].astype(int)\n",
    "train_df['not_alone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "deck = {\"A\": 1, \"B\": 2, \"C\": 3, \"D\": 4, \"E\": 5, \"F\": 6, \"G\": 7, \"U\": 8}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].fillna(\"U0\")\n",
    "    dataset['Deck'] = dataset['Cabin'].map(lambda x: re.compile(\"([a-zA-Z]+)\").search(x).group())\n",
    "    dataset['Deck'] = dataset['Deck'].map(deck)\n",
    "    dataset['Deck'] = dataset['Deck'].fillna(0)\n",
    "    dataset['Deck'] = dataset['Deck'].astype(int)\n",
    "    \n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    mean = train_df[\"Age\"].mean()\n",
    "    std = test_df[\"Age\"].std()\n",
    "    is_null = dataset[\"Age\"].isnull().sum()\n",
    "    \n",
    "    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n",
    "    \n",
    "    age_slice = dataset[\"Age\"].copy()\n",
    "    age_slice[np.isnan(age_slice)] = rand_age\n",
    "    dataset[\"Age\"] = age_slice\n",
    "    dataset[\"Age\"] = train_df[\"Age\"].astype(int)\n",
    "train_df[\"Age\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_value = 'S'\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna(common_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "block:featureengineering",
     "prev:datapreprocessing"
    ]
   },
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Fare'] = dataset['Fare'].fillna(0)\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "titles = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n",
    "\n",
    "for dataset in data:\n",
    "    # extract titles\n",
    "    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    # replace titles with a more common title or as Rare\n",
    "    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr',\\\n",
    "                                            'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n",
    "    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n",
    "    # convert titles into numbers\n",
    "    dataset['Title'] = dataset['Title'].map(titles)\n",
    "    # filling NaN with 0, to get safe\n",
    "    dataset['Title'] = dataset['Title'].fillna(0)\n",
    "train_df = train_df.drop(['Name'], axis=1)\n",
    "test_df = test_df.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "genders = {\"male\": 0, \"female\": 1}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(genders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(['Ticket'], axis=1)\n",
    "test_df = test_df.drop(['Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ports = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(ports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age'] = dataset['Age'].astype(int)\n",
    "    dataset.loc[ dataset['Age'] <= 11, 'Age'] = 0\n",
    "    dataset.loc[(dataset['Age'] > 11) & (dataset['Age'] <= 18), 'Age'] = 1\n",
    "    dataset.loc[(dataset['Age'] > 18) & (dataset['Age'] <= 22), 'Age'] = 2\n",
    "    dataset.loc[(dataset['Age'] > 22) & (dataset['Age'] <= 27), 'Age'] = 3\n",
    "    dataset.loc[(dataset['Age'] > 27) & (dataset['Age'] <= 33), 'Age'] = 4\n",
    "    dataset.loc[(dataset['Age'] > 33) & (dataset['Age'] <= 40), 'Age'] = 5\n",
    "    dataset.loc[(dataset['Age'] > 40) & (dataset['Age'] <= 66), 'Age'] = 6\n",
    "    dataset.loc[ dataset['Age'] > 66, 'Age'] = 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "\n",
    "for dataset in data:\n",
    "    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n",
    "    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n",
    "    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n",
    "    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 99), 'Fare']   = 3\n",
    "    dataset.loc[(dataset['Fare'] > 99) & (dataset['Fare'] <= 250), 'Fare']   = 4\n",
    "    dataset.loc[ dataset['Fare'] > 250, 'Fare'] = 5\n",
    "    dataset['Fare'] = dataset['Fare'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [train_df, test_df]\n",
    "for dataset in data:\n",
    "    dataset['Age_Class']= dataset['Age']* dataset['Pclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in data:\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare']/(dataset['relatives']+1)\n",
    "    dataset['Fare_Per_Person'] = dataset['Fare_Per_Person'].astype(int)\n",
    "# Let's take a last look at the training set, before we start training the models.\n",
    "# train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_df[PREDICTION_LABEL]\n",
    "train_df = train_df.drop(PREDICTION_LABEL, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "block:randomforest",
     "prev:featureengineering"
    ]
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(train_df, train_labels)\n",
    "acc_random_forest = round(random_forest.score(train_df, train_labels) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "block:logisticregression",
     "prev:featureengineering"
    ]
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver='lbfgs', max_iter=110)\n",
    "logreg.fit(train_df, train_labels)\n",
    "acc_log = round(logreg.score(train_df, train_labels) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [
     "block:naivebayes",
     "prev:featureengineering"
    ]
   },
   "outputs": [],
   "source": [
    "gaussian = GaussianNB()\n",
    "gaussian.fit(train_df, train_labels)\n",
    "acc_gaussian = round(gaussian.score(train_df, train_labels) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "block:svm",
     "prev:featureengineering"
    ]
   },
   "outputs": [],
   "source": [
    "linear_svc = SVC(gamma='auto')\n",
    "linear_svc.fit(train_df, train_labels)\n",
    "acc_linear_svc = round(linear_svc.score(train_df, train_labels) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [
     "block:decisiontree",
     "prev:featureengineering"
    ]
   },
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_df, train_labels)\n",
    "acc_decision_tree = round(decision_tree.score(train_df, train_labels) * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [
     "block:results",
     "prev:randomforest",
     "prev:logisticregression",
     "prev:naivebayes",
     "prev:svm",
     "prev:decisiontree"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Model\n",
      "Score                         \n",
      "92.70            Random Forest\n",
      "92.70            Decision Tree\n",
      "85.41  Support Vector Machines\n",
      "81.71      logistic Regression\n",
      "78.34              Naive Bayes\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame({\n",
    "    'Model': ['Support Vector Machines', 'logistic Regression',\n",
    "              'Random Forest', 'Naive Bayes', 'Decision Tree'],\n",
    "    'Score': [acc_linear_svc, acc_log,\n",
    "              acc_random_forest, acc_gaussian, acc_decision_tree]})\n",
    "result_df = results.sort_values(by='Score', ascending=False)\n",
    "result_df = result_df.set_index('Score')\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kubeflow_notebook": {
   "docker_image": "",
   "experiment_name": "titanic",
   "pipeline_description": "Predict which passengers survived the Titanic shipwreck",
   "pipeline_name": "titanic-ml",
   "volumes": []
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
